Number of epochs to train  1 gpu0
Start Train Script
The task:  Histologischer Subtyp  Classes:  ['Klassisch', 'DesmoNodlaer']
Image path-- /home/Mukherjee/MBlst/new_data_sets/4000
------------ Classes -------------
Number of Unique Patients 162
Number of patches all 2793
Label Frequency of patches:  [1598 1195]
Label Frequency of images given patients:  [104  58]
number of different patietns 162
Number of different Patients in Data Set 162
Patient Id [3, 6, 11, 12, 13, 15, 16, 21, 22, 28, 31, 34, 37, 38, 39, 41, 42, 46, 50, 53, 56, 58, 60, 63, 64, 71, 74, 77, 78, 79, 81, 84, 86, 87, 89, 90, 91, 93, 94, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 121, 124, 126, 131, 134, 139, 140, 143, 145, 149, 151, 157, 158, 159, 162, 164, 167, 168, 170, 171, 172, 176, 178, 179, 180, 182, 187, 188, 190, 191, 193, 194, 195, 197, 200, 201, 204, 205, 208, 209, 210, 213, 214, 216, 221, 222, 224, 227, 229, 230, 232, 238, 244, 245, 248, 249, 254, 256, 257, 258, 259, 261, 263, 270, 271, 273, 274, 275, 277, 280, 282, 284, 286, 287, 291, 292, 295, 297, 299, 302, 304, 306, 307, 309, 310, 314, 318, 320, 321, 322, 324, 325, 326, 328, 330, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 348, 349, 351] 162
175
162
After Split Config
Checking for GPU
True
 USING GPUs [0]
Evaluating on validation set during training.
Loaded pretrained weights for efficientnet-b0
Loaded pretrained weights for efficientnet-b5
/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  f"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, "
/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
print the devices cuda:0
cuda:0
Load old 0
Current class weights [1.57446809 2.74074074]
Current class weights with extra [1.57446809 2.74074074]
Dataset Train 148ta: |█████████████████████████████████████████████████-| 99.3% Complete
Dataset Val 344
**** Batch Size ;;: 20 [0]
The task:  Histologischer Subtyp  Classes:  ['Klassisch', 'DesmoNodlaer']
Image path-- /home/Mukherjee/MBlst/new_data_sets/2000
------------ Classes -------------
Number of Unique Patients 162
Number of patches all 2793
Label Frequency of patches:  [1598 1195]
Label Frequency of images given patients:  [104  58]
number of different patietns 162
Number of different Patients in Data Set 162
Patient Id [3, 6, 11, 12, 13, 15, 16, 21, 22, 28, 31, 34, 37, 38, 39, 41, 42, 46, 50, 53, 56, 58, 60, 63, 64, 71, 74, 77, 78, 79, 81, 84, 86, 87, 89, 90, 91, 93, 94, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 121, 124, 126, 131, 134, 139, 140, 143, 145, 149, 151, 157, 158, 159, 162, 164, 167, 168, 170, 171, 172, 176, 178, 179, 180, 182, 187, 188, 190, 191, 193, 194, 195, 197, 200, 201, 204, 205, 208, 209, 210, 213, 214, 216, 221, 222, 224, 227, 229, 230, 232, 238, 244, 245, 248, 249, 254, 256, 257, 258, 259, 261, 263, 270, 271, 273, 274, 275, 277, 280, 282, 284, 286, 287, 291, 292, 295, 297, 299, 302, 304, 306, 307, 309, 310, 314, 318, 320, 321, 322, 324, 325, 326, 328, 330, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 348, 349, 351] 162
175
162
trainind 1323
The task:  Histologischer Subtyp  Classes:  ['Klassisch', 'DesmoNodlaer'] 99.3% Complete
Image path-- /home/Mukherjee/MBlst/new_data_sets/4000
------------ Classes -------------
Number of Unique Patients 162
Number of patches all 2793
Label Frequency of patches:  [1598 1195]
Label Frequency of images given patients:  [104  58]
number of different patietns 162
Number of different Patients in Data Set 162
Patient Id [3, 6, 11, 12, 13, 15, 16, 21, 22, 28, 31, 34, 37, 38, 39, 41, 42, 46, 50, 53, 56, 58, 60, 63, 64, 71, 74, 77, 78, 79, 81, 84, 86, 87, 89, 90, 91, 93, 94, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 121, 124, 126, 131, 134, 139, 140, 143, 145, 149, 151, 157, 158, 159, 162, 164, 167, 168, 170, 171, 172, 176, 178, 179, 180, 182, 187, 188, 190, 191, 193, 194, 195, 197, 200, 201, 204, 205, 208, 209, 210, 213, 214, 216, 221, 222, 224, 227, 229, 230, 232, 238, 244, 245, 248, 249, 254, 256, 257, 258, 259, 261, 263, 270, 271, 273, 274, 275, 277, 280, 282, 284, 286, 287, 291, 292, 295, 297, 299, 302, 304, 306, 307, 309, 310, 314, 318, 320, 321, 322, 324, 325, 326, 328, 330, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 348, 349, 351] 162
175
162
trainind 1323
The task:  Histologischer Subtyp  Classes:  ['Klassisch', 'DesmoNodlaer'] 99.3% Complete
Image path-- /home/Mukherjee/MBlst/new_data_sets/8000
------------ Classes -------------
Number of Unique Patients 162
Number of patches all 2793
Label Frequency of patches:  [1598 1195]
Label Frequency of images given patients:  [104  58]
number of different patietns 162
Number of different Patients in Data Set 162
Patient Id [3, 6, 11, 12, 13, 15, 16, 21, 22, 28, 31, 34, 37, 38, 39, 41, 42, 46, 50, 53, 56, 58, 60, 63, 64, 71, 74, 77, 78, 79, 81, 84, 86, 87, 89, 90, 91, 93, 94, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 121, 124, 126, 131, 134, 139, 140, 143, 145, 149, 151, 157, 158, 159, 162, 164, 167, 168, 170, 171, 172, 176, 178, 179, 180, 182, 187, 188, 190, 191, 193, 194, 195, 197, 200, 201, 204, 205, 208, 209, 210, 213, 214, 216, 221, 222, 224, 227, 229, 230, 232, 238, 244, 245, 248, 249, 254, 256, 257, 258, 259, 261, 263, 270, 271, 273, 274, 275, 277, 280, 282, 284, 286, 287, 291, 292, 295, 297, 299, 302, 304, 306, 307, 309, 310, 314, 318, 320, 321, 322, 324, 325, 326, 328, 330, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 348, 349, 351] 162
175
162
trainind 1323
Train,Val,test 148 344 344█████████████████████████████████████████████-| 99.3% Complete
Recieved Model1
The Model is  efficientnet_b0
******---*** MODEL LOADED TO GPU/CPU *****---***
Train all Weights
Number of training Parameters 658947
Number of training Parameters 658947
Epoch 0:   0%|                                                                                                                                                         | 0/7 [00:00<?, ?it/s]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name  | Type          | Params
----------------------------------------
0 | model | Eff_attention | 4.7 M
----------------------------------------
658 K     Trainable params
4.0 M     Non-trainable params
4.7 M     Total params
18.666    Total estimated model params size (MB)
/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1896: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Epoch 0:   0%|                                                                                                                                                         | 0/7 [00:00<?, ?it/s]batch_idx 0
idx tensor([ 26,  24, 110,  28,  95, 128, 113, 121,  81,  10, 141, 142,  80,  89,
         55,  11,  34,  20,  71,  94], device='cuda:0')
x 20
1  torch.Size([20, 12, 3, 224, 224])
0 torch.Size([20, 12, 3, 224, 224])
4  torch.Size([240, 1280])
6  torch.Size([240, 1])
7  torch.Size([1, 240])
7  torch.Size([1, 240])
8  torch.Size([60, 4])
9 tensor([[[-3.9251, -3.1264, -2.0779,  ..., -4.3639, -2.1771, -0.8786],
         [-6.5361, -3.5066, -2.6733,  ..., -2.3348, -0.4497, -2.4884],
         [-3.8003,  0.0000,  0.0000,  ..., -0.5874,  1.3273, -0.3967],
         [-0.5746, -3.0322, -2.8832,  ...,  0.0000, -1.9441, -3.5648]],
        [[-2.5294,  0.0000,  0.0000,  ..., -5.8627, -5.1615, -0.2310],
         [-3.4022,  0.0000, -0.1938,  ..., -1.3101, -2.2408, -0.8866],
         [ 0.0000, -2.2265,  0.0000,  ..., -4.9164, -3.0894, -2.2934],
         [-3.2759, -5.8350, -5.5982,  ..., -1.6749, -4.8701, -1.7989]],
        [[ 0.0000,  0.0000, -1.8100,  ...,  0.0000, -2.9008, -0.8418],
         [-5.0896, -0.8114, -2.9305,  ...,  1.1329, -0.2279, -1.7266],
         [ 0.0000, -3.1151,  0.0000,  ...,  0.0000, -0.5142,  0.8809],
         [-1.1694, -3.2093,  0.0000,  ...,  0.1198, -3.1078,  0.0186]],
        ...,
        [[ 0.0000, -4.9692,  0.0000,  ..., -3.3684,  0.0000, -2.0381],
         [-0.6064, -4.3118,  0.0000,  ..., -4.5427, -1.0832,  0.0000],
         [ 0.3385, -1.5104, -2.2005,  ...,  0.0000,  0.0000,  0.1763],
         [ 0.0000, -3.9162, -3.0539,  ..., -3.6159, -5.8860, -1.3560]],
        [[-4.8173,  0.0000,  0.0000,  ...,  0.0000, -6.8391, -2.9464],
         [ 0.0000,  0.0000, -3.8707,  ...,  0.0000,  0.0000, -1.3017],
         [-1.2934, -2.7770, -3.5939,  ...,  0.7633, -1.1674,  0.0000],
         [-2.2127, -4.2624, -5.3503,  ..., -3.2206, -4.7649, -0.2813]],
        [[-3.3922, -0.0110,  0.0000,  ..., -4.6029, -5.4294,  0.7644],
         [-4.7479, -0.4349, -2.4118,  ..., -3.2543, -0.4700, -0.2444],
         [-3.1310, -0.0248, -1.8070,  ..., -3.8718, -2.3381,  0.0000],
         [ 0.3404,  0.0000, -2.4381,  ..., -2.6843,  0.0000, -4.8570]]],
       device='cuda:0') torch.Size([20, 4, 3840])
10  0 torch.Size([1, 3840])
Traceback (most recent call last):
  File "multimag_train_test.py", line 1021, in <module>
    trainer.fit(model = classify_model,train_dataloaders = modelVars['dataloader_trainInd'], val_dataloaders = modelVars['dataloader_valInd'])
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 697, in fit
    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 735, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1166, in _run
    results = self._run_stage()
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1252, in _run_stage
    return self._run_train()
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1283, in _run_train
    self.fit_loop.run()
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/fit_loop.py", line 271, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 203, in advance
    batch_output = self.batch_loop.run(kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 87, in advance
    outputs = self.optimizer_loop.run(optimizers, kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 201, in advance
    result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 248, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, kwargs.get("batch_idx", 0), closure)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 367, in _optimizer_step
    using_lbfgs=is_lbfgs,
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1550, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/core/module.py", line 1705, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/strategies/strategy.py", line 216, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 153, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/optim/optimizer.py", line 113, in wrapper
    return func(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/optim/adam.py", line 118, in step
    loss = closure()
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 138, in _wrap_closure
    closure_result = closure()
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 132, in closure
    step_output = self._step_fn()
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 407, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *kwargs.values())
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1704, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/strategies/strategy.py", line 358, in training_step
    return self.model.training_step(*args, **kwargs)
  File "multimag_train_test.py", line 252, in training_step
    outputs = self.model(x,'train')
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "multimag_train_test.py", line 617, in forward
    Y_prob = self.classifier(M)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x3840 and 1280x2)