Number of epochs to train  1 gpu0
Start Train Script
The task:  Histologischer Subtyp  Classes:  ['Klassisch', 'DesmoNodlaer']
Image path-- /home/Mukherjee/MBlst/new_data_sets/4000
------------ Classes -------------
Number of Unique Patients 162
Number of patches all 2793
Label Frequency of patches:  [1598 1195]
Label Frequency of images given patients:  [104  58]
number of different patietns 162
Number of different Patients in Data Set 162
Patient Id [3, 6, 11, 12, 13, 15, 16, 21, 22, 28, 31, 34, 37, 38, 39, 41, 42, 46, 50, 53, 56, 58, 60, 63, 64, 71, 74, 77, 78, 79, 81, 84, 86, 87, 89, 90, 91, 93, 94, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 121, 124, 126, 131, 134, 139, 140, 143, 145, 149, 151, 157, 158, 159, 162, 164, 167, 168, 170, 171, 172, 176, 178, 179, 180, 182, 187, 188, 190, 191, 193, 194, 195, 197, 200, 201, 204, 205, 208, 209, 210, 213, 214, 216, 221, 222, 224, 227, 229, 230, 232, 238, 244, 245, 248, 249, 254, 256, 257, 258, 259, 261, 263, 270, 271, 273, 274, 275, 277, 280, 282, 284, 286, 287, 291, 292, 295, 297, 299, 302, 304, 306, 307, 309, 310, 314, 318, 320, 321, 322, 324, 325, 326, 328, 330, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 348, 349, 351] 162
175
162
After Split Config
Checking for GPU
True
 USING GPUs [0]
Evaluating on validation set during training.
Loaded pretrained weights for efficientnet-b0
/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  f"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, "
/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Loaded pretrained weights for efficientnet-b5
print the devices cuda:0
cuda:0
Load old 0
Current class weights [1.57446809 2.74074074]
Current class weights with extra [1.57446809 2.74074074]
Dataset Train 148ta: |█████████████████████████████████████████████████-| 99.3% Complete
Dataset Val 344
**** Batch Size ;;: 20 [0]
The task:  Histologischer Subtyp  Classes:  ['Klassisch', 'DesmoNodlaer']
Image path-- /home/Mukherjee/MBlst/new_data_sets/2000
------------ Classes -------------
Number of Unique Patients 162
Number of patches all 2793
Label Frequency of patches:  [1598 1195]
Label Frequency of images given patients:  [104  58]
number of different patietns 162
Number of different Patients in Data Set 162
Patient Id [3, 6, 11, 12, 13, 15, 16, 21, 22, 28, 31, 34, 37, 38, 39, 41, 42, 46, 50, 53, 56, 58, 60, 63, 64, 71, 74, 77, 78, 79, 81, 84, 86, 87, 89, 90, 91, 93, 94, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 121, 124, 126, 131, 134, 139, 140, 143, 145, 149, 151, 157, 158, 159, 162, 164, 167, 168, 170, 171, 172, 176, 178, 179, 180, 182, 187, 188, 190, 191, 193, 194, 195, 197, 200, 201, 204, 205, 208, 209, 210, 213, 214, 216, 221, 222, 224, 227, 229, 230, 232, 238, 244, 245, 248, 249, 254, 256, 257, 258, 259, 261, 263, 270, 271, 273, 274, 275, 277, 280, 282, 284, 286, 287, 291, 292, 295, 297, 299, 302, 304, 306, 307, 309, 310, 314, 318, 320, 321, 322, 324, 325, 326, 328, 330, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 348, 349, 351] 162
175
162
trainind 1323
The task:  Histologischer Subtyp  Classes:  ['Klassisch', 'DesmoNodlaer'] 99.3% Complete
Image path-- /home/Mukherjee/MBlst/new_data_sets/4000
------------ Classes -------------
Number of Unique Patients 162
Number of patches all 2793
Label Frequency of patches:  [1598 1195]
Label Frequency of images given patients:  [104  58]
number of different patietns 162
Number of different Patients in Data Set 162
Patient Id [3, 6, 11, 12, 13, 15, 16, 21, 22, 28, 31, 34, 37, 38, 39, 41, 42, 46, 50, 53, 56, 58, 60, 63, 64, 71, 74, 77, 78, 79, 81, 84, 86, 87, 89, 90, 91, 93, 94, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 121, 124, 126, 131, 134, 139, 140, 143, 145, 149, 151, 157, 158, 159, 162, 164, 167, 168, 170, 171, 172, 176, 178, 179, 180, 182, 187, 188, 190, 191, 193, 194, 195, 197, 200, 201, 204, 205, 208, 209, 210, 213, 214, 216, 221, 222, 224, 227, 229, 230, 232, 238, 244, 245, 248, 249, 254, 256, 257, 258, 259, 261, 263, 270, 271, 273, 274, 275, 277, 280, 282, 284, 286, 287, 291, 292, 295, 297, 299, 302, 304, 306, 307, 309, 310, 314, 318, 320, 321, 322, 324, 325, 326, 328, 330, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 348, 349, 351] 162
175
162
trainind 1323
The task:  Histologischer Subtyp  Classes:  ['Klassisch', 'DesmoNodlaer'] 99.3% Complete
Image path-- /home/Mukherjee/MBlst/new_data_sets/8000
------------ Classes -------------
Number of Unique Patients 162
Number of patches all 2793
Label Frequency of patches:  [1598 1195]
Label Frequency of images given patients:  [104  58]
number of different patietns 162
Number of different Patients in Data Set 162
Patient Id [3, 6, 11, 12, 13, 15, 16, 21, 22, 28, 31, 34, 37, 38, 39, 41, 42, 46, 50, 53, 56, 58, 60, 63, 64, 71, 74, 77, 78, 79, 81, 84, 86, 87, 89, 90, 91, 93, 94, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 121, 124, 126, 131, 134, 139, 140, 143, 145, 149, 151, 157, 158, 159, 162, 164, 167, 168, 170, 171, 172, 176, 178, 179, 180, 182, 187, 188, 190, 191, 193, 194, 195, 197, 200, 201, 204, 205, 208, 209, 210, 213, 214, 216, 221, 222, 224, 227, 229, 230, 232, 238, 244, 245, 248, 249, 254, 256, 257, 258, 259, 261, 263, 270, 271, 273, 274, 275, 277, 280, 282, 284, 286, 287, 291, 292, 295, 297, 299, 302, 304, 306, 307, 309, 310, 314, 318, 320, 321, 322, 324, 325, 326, 328, 330, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 348, 349, 351] 162
175
162
trainind 1323
Train,Val,test 148 344 344█████████████████████████████████████████████-| 99.3% Complete
Recieved Model1
L 1280
The Model is  efficientnet_b0
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
******---*** MODEL LOADED TO GPU/CPU *****---***
Train all Weights
Number of training Parameters 658947
Number of training Parameters 658947
Epoch 0:   0%|                                                                                                                                                         | 0/7 [00:00<?, ?it/s]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name  | Type          | Params
----------------------------------------
0 | model | Eff_attention | 4.7 M
----------------------------------------
658 K     Trainable params
4.0 M     Non-trainable params
4.7 M     Total params
18.666    Total estimated model params size (MB)
/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1896: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Epoch 0:   0%|                                                                                                                                                         | 0/7 [00:00<?, ?it/s]batch_idx 0
idx tensor([ 41,  55, 111,  20,  71,  88, 144,   7, 112, 124, 119,   8,  59,   0,
        132,  48,  19,  74,  14, 110], device='cuda:0')
x 20
X1  torch.Size([20, 12, 3, 224, 224])
X2 torch.Size([20, 12, 3, 224, 224])
H4  torch.Size([240, 1280])
A5  torch.Size([240, 1])
A6  torch.Size([1, 240])
A7  torch.Size([60, 4])
A8  torch.Size([60, 4])
H9 torch.Size([20, 4, 3840])
In Loop 0 torch.Size([1, 4]) torch.Size([4, 3840])
10  torch.Size([1, 3840])
Traceback (most recent call last):
  File "multimag_train_test.py", line 1024, in <module>
    trainer.fit(model = classify_model,train_dataloaders = modelVars['dataloader_trainInd'], val_dataloaders = modelVars['dataloader_valInd'])
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 697, in fit
    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 735, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1166, in _run
    results = self._run_stage()
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1252, in _run_stage
    return self._run_train()
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1283, in _run_train
    self.fit_loop.run()
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/fit_loop.py", line 271, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 203, in advance
    batch_output = self.batch_loop.run(kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 87, in advance
    outputs = self.optimizer_loop.run(optimizers, kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py", line 200, in run
    self.advance(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 201, in advance
    result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 248, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, kwargs.get("batch_idx", 0), closure)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 367, in _optimizer_step
    using_lbfgs=is_lbfgs,
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1550, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/core/module.py", line 1705, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/core/optimizer.py", line 168, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/strategies/strategy.py", line 216, in optimizer_step
    return self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 153, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/optim/optimizer.py", line 113, in wrapper
    return func(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/optim/adam.py", line 118, in step
    loss = closure()
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py", line 138, in _wrap_closure
    closure_result = closure()
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 132, in closure
    step_output = self._step_fn()
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 407, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *kwargs.values())
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1704, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/strategies/strategy.py", line 358, in training_step
    return self.model.training_step(*args, **kwargs)
  File "multimag_train_test.py", line 252, in training_step
    outputs = self.model(x,'train')
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "multimag_train_test.py", line 620, in forward
    Y_prob = self.classifier(M)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x3840 and 1280x2)