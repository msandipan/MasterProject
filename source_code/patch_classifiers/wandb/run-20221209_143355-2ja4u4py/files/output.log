Number of epochs to train  1 gpu0
Start Train Script
The task:  Histologischer Subtyp  Classes:  ['Klassisch', 'DesmoNodlaer']
Image path-- /home/Mukherjee/MBlst/new_data_sets/4000
------------ Classes -------------
Number of Unique Patients 162
Number of patches all 2793
Label Frequency of patches:  [1598 1195]
Label Frequency of images given patients:  [104  58]
number of different patietns 162
Number of different Patients in Data Set 162
Patient Id [3, 6, 11, 12, 13, 15, 16, 21, 22, 28, 31, 34, 37, 38, 39, 41, 42, 46, 50, 53, 56, 58, 60, 63, 64, 71, 74, 77, 78, 79, 81, 84, 86, 87, 89, 90, 91, 93, 94, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 121, 124, 126, 131, 134, 139, 140, 143, 145, 149, 151, 157, 158, 159, 162, 164, 167, 168, 170, 171, 172, 176, 178, 179, 180, 182, 187, 188, 190, 191, 193, 194, 195, 197, 200, 201, 204, 205, 208, 209, 210, 213, 214, 216, 221, 222, 224, 227, 229, 230, 232, 238, 244, 245, 248, 249, 254, 256, 257, 258, 259, 261, 263, 270, 271, 273, 274, 275, 277, 280, 282, 284, 286, 287, 291, 292, 295, 297, 299, 302, 304, 306, 307, 309, 310, 314, 318, 320, 321, 322, 324, 325, 326, 328, 330, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 348, 349, 351] 162
175
162
After Split Config
Checking for GPU
True
 USING GPUs [0]
Evaluating on validation set during training.
Loaded pretrained weights for efficientnet-b0
/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  f"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, "
/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
Loaded pretrained weights for efficientnet-b5
print the devices cuda:0
cuda:0
Load old 0
Current class weights [1.57446809 2.74074074]
Current class weights with extra [1.57446809 2.74074074]
Dataset Train 148ta: |█████████████████████████████████████████████████-| 99.3% Complete
Dataset Val 344
**** Batch Size ;;: 20 [0]
The task:  Histologischer Subtyp  Classes:  ['Klassisch', 'DesmoNodlaer']
Image path-- /home/Mukherjee/MBlst/new_data_sets/2000
------------ Classes -------------
Number of Unique Patients 162
Number of patches all 2793
Label Frequency of patches:  [1598 1195]
Label Frequency of images given patients:  [104  58]
number of different patietns 162
Number of different Patients in Data Set 162
Patient Id [3, 6, 11, 12, 13, 15, 16, 21, 22, 28, 31, 34, 37, 38, 39, 41, 42, 46, 50, 53, 56, 58, 60, 63, 64, 71, 74, 77, 78, 79, 81, 84, 86, 87, 89, 90, 91, 93, 94, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 121, 124, 126, 131, 134, 139, 140, 143, 145, 149, 151, 157, 158, 159, 162, 164, 167, 168, 170, 171, 172, 176, 178, 179, 180, 182, 187, 188, 190, 191, 193, 194, 195, 197, 200, 201, 204, 205, 208, 209, 210, 213, 214, 216, 221, 222, 224, 227, 229, 230, 232, 238, 244, 245, 248, 249, 254, 256, 257, 258, 259, 261, 263, 270, 271, 273, 274, 275, 277, 280, 282, 284, 286, 287, 291, 292, 295, 297, 299, 302, 304, 306, 307, 309, 310, 314, 318, 320, 321, 322, 324, 325, 326, 328, 330, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 348, 349, 351] 162
175
162
trainind 1323
The task:  Histologischer Subtyp  Classes:  ['Klassisch', 'DesmoNodlaer'] 99.3% Complete
Image path-- /home/Mukherjee/MBlst/new_data_sets/4000
------------ Classes -------------
Number of Unique Patients 162
Number of patches all 2793
Label Frequency of patches:  [1598 1195]
Label Frequency of images given patients:  [104  58]
number of different patietns 162
Number of different Patients in Data Set 162
Patient Id [3, 6, 11, 12, 13, 15, 16, 21, 22, 28, 31, 34, 37, 38, 39, 41, 42, 46, 50, 53, 56, 58, 60, 63, 64, 71, 74, 77, 78, 79, 81, 84, 86, 87, 89, 90, 91, 93, 94, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 121, 124, 126, 131, 134, 139, 140, 143, 145, 149, 151, 157, 158, 159, 162, 164, 167, 168, 170, 171, 172, 176, 178, 179, 180, 182, 187, 188, 190, 191, 193, 194, 195, 197, 200, 201, 204, 205, 208, 209, 210, 213, 214, 216, 221, 222, 224, 227, 229, 230, 232, 238, 244, 245, 248, 249, 254, 256, 257, 258, 259, 261, 263, 270, 271, 273, 274, 275, 277, 280, 282, 284, 286, 287, 291, 292, 295, 297, 299, 302, 304, 306, 307, 309, 310, 314, 318, 320, 321, 322, 324, 325, 326, 328, 330, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 348, 349, 351] 162
175
162
trainind 1323
The task:  Histologischer Subtyp  Classes:  ['Klassisch', 'DesmoNodlaer'] 99.3% Complete
Image path-- /home/Mukherjee/MBlst/new_data_sets/8000
------------ Classes -------------
Number of Unique Patients 162
Number of patches all 2793
Label Frequency of patches:  [1598 1195]
Label Frequency of images given patients:  [104  58]
number of different patietns 162
Number of different Patients in Data Set 162
Patient Id [3, 6, 11, 12, 13, 15, 16, 21, 22, 28, 31, 34, 37, 38, 39, 41, 42, 46, 50, 53, 56, 58, 60, 63, 64, 71, 74, 77, 78, 79, 81, 84, 86, 87, 89, 90, 91, 93, 94, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 121, 124, 126, 131, 134, 139, 140, 143, 145, 149, 151, 157, 158, 159, 162, 164, 167, 168, 170, 171, 172, 176, 178, 179, 180, 182, 187, 188, 190, 191, 193, 194, 195, 197, 200, 201, 204, 205, 208, 209, 210, 213, 214, 216, 221, 222, 224, 227, 229, 230, 232, 238, 244, 245, 248, 249, 254, 256, 257, 258, 259, 261, 263, 270, 271, 273, 274, 275, 277, 280, 282, 284, 286, 287, 291, 292, 295, 297, 299, 302, 304, 306, 307, 309, 310, 314, 318, 320, 321, 322, 324, 325, 326, 328, 330, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 348, 349, 351] 162
175
162
trainind 1323
Train,Val,test 148 344 344█████████████████████████████████████████████-| 99.3% Complete
Recieved Model1
L 1280
The Model is  efficientnet_b0
******---*** MODEL LOADED TO GPU/CPU *****---***
Train all Weights
Number of training Parameters 658947
Number of training Parameters 658947
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name  | Type          | Params
----------------------------------------
0 | model | Eff_attention | 4.7 M
----------------------------------------
658 K     Trainable params
4.0 M     Non-trainable params
4.7 M     Total params
18.666    Total estimated model params size (MB)
/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1896: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  category=PossibleUserWarning,
Epoch 0:   0%|                                                                                                                                                         | 0/7 [00:00<?, ?it/s]batch_idx 0
idx tensor([ 97,  46,  34,  25,  45,  33,  55, 146,   7, 139, 136,  57,   9,  86,
        112, 126, 122, 113, 109,  29], device='cuda:0')
x 20
X1  torch.Size([20, 12, 3, 224, 224])
X2 torch.Size([20, 12, 3, 224, 224])
H4  torch.Size([240, 1280])
A5  torch.Size([240, 1])
A6  torch.Size([1, 240])
A7  torch.Size([20, 12])
A8  torch.Size([20, 12])
H9 torch.Size([20, 12, 1280])
In Loop 0 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.9696, 0.4567]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 1 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.3881, 0.2657]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 2 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7589, 0.3888]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 3 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.3680, 0.2850]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 4 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6715, 0.3358]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 5 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8142, 0.3929]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 6 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7629, 0.5033]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 7 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7035, 0.3676]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 8 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8573, 0.5479]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 9 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6442, 0.3788]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 10 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6518, 0.6430]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 11 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8196, 0.3116]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 12 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8596, 0.2170]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 13 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7606, 0.5726]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 14 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.9073, 0.5511]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 15 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8593, 0.6996]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 16 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7387, 0.1958]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 17 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8734, 0.5474]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 18 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7886, 0.6392]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 19 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7581, 0.3475]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
output length 20
output tensor([[0.9696, 0.4567],
        [0.3881, 0.2657],
        [0.7589, 0.3888],
        [0.3680, 0.2850],
        [0.6715, 0.3358],
        [0.8142, 0.3929],
        [0.7629, 0.5033],
        [0.7035, 0.3676],
        [0.8573, 0.5479],
        [0.6442, 0.3788],
        [0.6518, 0.6430],
        [0.8196, 0.3116],
        [0.8596, 0.2170],
        [0.7606, 0.5726],
        [0.9073, 0.5511],
        [0.8593, 0.6996],
        [0.7387, 0.1958],
        [0.8734, 0.5474],
        [0.7886, 0.6392],
        [0.7581, 0.3475]], device='cuda:0', grad_fn=<CatBackward0>)
labels tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1],
       device='cuda:0')
Epoch 0:  14%|█████████████████▍                                                                                                        | 1/7 [03:05<18:34, 185.80s/it, loss=0.681, v_num=22]batch_idx 1
idx tensor([134, 101,  88,  19,  12, 129,  13, 140,  11, 142,   8,  61,  96,  92,
        115,  93,  75,  87, 102,  35], device='cuda:0')
x 20
X1  torch.Size([20, 12, 3, 224, 224])
X2 torch.Size([20, 12, 3, 224, 224])
H4  torch.Size([240, 1280])
A5  torch.Size([240, 1])
A6  torch.Size([1, 240])
A7  torch.Size([20, 12])
A8  torch.Size([20, 12])
H9 torch.Size([20, 12, 1280])
In Loop 0 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11
/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:233: UserWarning: You called `self.log('ensemble_count', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.
X2 torch.Size([20, 12, 3, 224, 224])e='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 1 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.4996, 0.4330]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 2 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7897, 0.5673]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 3 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8823, 0.4490]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 4 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7263, 0.2810]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 5 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7448, 0.3766]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 6 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8302, 0.7435]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 7 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.5413, 0.5678]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 8 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7015, 0.5916]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 9 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7353, 0.4958]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 10 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6279, 0.3500]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 11 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8330, 0.6680]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 12 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.5690, 0.2552]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 13 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6814, 0.3826]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 14 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6732, 0.6084]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 15 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.5404, 0.6310]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 16 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7390, 0.3838]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 17 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8736, 0.5310]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 18 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.3791, 0.8151]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 19 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6758, 0.3695]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
output length 20
output tensor([[0.7777, 0.5299],
        [0.4996, 0.4330],
        [0.7897, 0.5673],
        [0.8823, 0.4490],
        [0.7263, 0.2810],
        [0.7448, 0.3766],
        [0.8302, 0.7435],
        [0.5413, 0.5678],
        [0.7015, 0.5916],
        [0.7353, 0.4958],
        [0.6279, 0.3500],
        [0.8330, 0.6680],
        [0.5690, 0.2552],
        [0.6814, 0.3826],
        [0.6732, 0.6084],
        [0.5404, 0.6310],
        [0.7390, 0.3838],
        [0.8736, 0.5310],
        [0.3791, 0.8151],
        [0.6758, 0.3695]], device='cuda:0', grad_fn=<CatBackward0>)
labels tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1],
       device='cuda:0')
Epoch 0:  29%|███████████████████████████████████▏                                                                                       | 2/7 [03:06<07:45, 93.11s/it, loss=0.691, v_num=22]batch_idx 2
idx tensor([ 68, 133, 121,  76, 100,  47,  18, 119,  48,  37,  85,  21, 117, 145,
         26,  91, 143, 103,  30,  95], device='cuda:0')
x 20
X1  torch.Size([20, 12, 3, 224, 224])
X2 torch.Size([20, 12, 3, 224, 224])e='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
H4  torch.Size([240, 1280])
A5  torch.Size([240, 1])
A6  torch.Size([1, 240])
A7  torch.Size([20, 12])
A8  torch.Size([20, 12])
H9 torch.Size([20, 12, 1280])
In Loop 0 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7056, 0.6394]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 1 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.9273, 0.5165]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 2 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6660, 0.6414]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 3 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7618, 0.4510]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 4 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8230, 0.5376]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 5 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8409, 0.4174]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 6 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7517, 0.3852]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 7 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8688, 0.4488]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 8 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8095, 0.2944]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 9 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6142, 0.6731]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 10 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8388, 0.6671]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 11 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.5393, 0.4538]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 12 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6401, 0.3453]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 13 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8052, 0.2833]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 14 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7344, 0.3231]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 15 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7648, 0.3663]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 16 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7262, 0.4748]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 17 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6462, 0.2065]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 18 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8010, 0.5015]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 19 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7530, 0.6099]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
output length 20
output tensor([[0.7056, 0.6394],
        [0.9273, 0.5165],
        [0.6660, 0.6414],
        [0.7618, 0.4510],
        [0.8230, 0.5376],
        [0.8409, 0.4174],
        [0.7517, 0.3852],
        [0.8688, 0.4488],
        [0.8095, 0.2944],
        [0.6142, 0.6731],
        [0.8388, 0.6671],
        [0.5393, 0.4538],
        [0.6401, 0.3453],
        [0.8052, 0.2833],
        [0.7344, 0.3231],
        [0.7648, 0.3663],
        [0.7262, 0.4748],
        [0.6462, 0.2065],
        [0.8010, 0.5015],
        [0.7530, 0.6099]], device='cuda:0', grad_fn=<CatBackward0>)
labels tensor([1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0],
       device='cuda:0')
Epoch 0:  43%|████████████████████████████████████████████████████▋                                                                      | 3/7 [03:07<04:10, 62.59s/it, loss=0.697, v_num=22]batch_idx 3
idx tensor([ 31,  79,  98,  38,  80,  23,  62,  56,  83,  44, 106,  15, 141,  40,
         58,  49,  73, 125,  70, 123], device='cuda:0')
x 20
X1  torch.Size([20, 12, 3, 224, 224])
X2 torch.Size([20, 12, 3, 224, 224])
H4  torch.Size([240, 1280])
A5  torch.Size([240, 1])
A6  torch.Size([1, 240])
A7  torch.Size([20, 12])
A8  torch.Size([20, 12])
H9 torch.Size([20, 12, 1280])
In Loop 0 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.2998, 0.4175]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 1 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6759, 0.5782]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 2 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7190, 0.2911]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 3 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8646, 0.5287]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 4 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8706, 0.5823]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 5 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.4382, 0.2125]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 6 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7954, 0.2844]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 7 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8709, 0.6812]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 8 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.5532, 0.5096]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 9 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7095, 0.6579]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 10 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7217, 0.7215]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 11 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.5766, 0.3750]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 12 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8456, 0.5434]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 13 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.5168, 0.3576]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 14 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6317, 0.2924]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 15 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8878, 0.8465]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 16 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8649, 0.4516]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 17 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8290, 0.6632]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 18 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8216, 0.5873]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 19 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6942, 0.1588]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
output length 20
output tensor([[0.2998, 0.4175],
        [0.6759, 0.5782],
        [0.7190, 0.2911],
        [0.8646, 0.5287],
        [0.8706, 0.5823],
        [0.4382, 0.2125],
        [0.7954, 0.2844],
        [0.8709, 0.6812],
        [0.5532, 0.5096],
        [0.7095, 0.6579],
        [0.7217, 0.7215],
        [0.5766, 0.3750],
        [0.8456, 0.5434],
        [0.5168, 0.3576],
        [0.6317, 0.2924],
        [0.8878, 0.8465],
        [0.8649, 0.4516],
        [0.8290, 0.6632],
        [0.8216, 0.5873],
        [0.6942, 0.1588]], device='cuda:0', grad_fn=<CatBackward0>)
labels tensor([0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
       device='cuda:0')
Epoch 0:  57%|██████████████████████████████████████████████████████████████████████▎                                                    | 4/7 [03:08<02:21, 47.22s/it, loss=0.698, v_num=22]
        [0.5992, 0.3701],█████████████████████████████████████████▋                                                                      | 3/7 [03:07<04:10, 62.59s/it, loss=0.697, v_num=22]batch_idx 3
        [0.5865, 0.7640],
        [0.5729, 0.5404],
        [0.7303, 0.6738],
        [0.7755, 0.7845],
        [0.7955, 0.5510],
        [0.7659, 0.8120],
        [0.8945, 0.3728],
        [0.6322, 0.6896],
        [0.8120, 0.6042],
        [0.4354, 0.3246],
        [0.6553, 0.5957]], device='cuda:0', grad_fn=<CatBackward0>)
labels tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0],
       device='cuda:0')
Epoch 0:  71%|███████████████████████████████████████████████████████████████████████████████████████▊                                   | 5/7 [05:40<02:16, 68.19s/it, loss=0.691, v_num=22]batch_idx 5
idx tensor([ 84, 114, 105, 116, 144,  64,  14,   0,  60, 110,  24,   4, 147,  54,
        135,  78,  77,  51,  22,  63], device='cuda:0')
x 20
X1  torch.Size([20, 12, 3, 224, 224])
X2 torch.Size([20, 12, 3, 224, 224])
H4  torch.Size([240, 1280])
A5  torch.Size([240, 1])
A6  torch.Size([1, 240])
A7  torch.Size([20, 12])
A8  torch.Size([20, 12])
H9 torch.Size([20, 12, 1280])
In Loop 0 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8214, 0.5659]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 1 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6871, 0.3903]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 2 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.5410, 0.1635]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 3 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6328, 0.3244]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 4 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8015, 0.8223]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 5 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7505, 0.5803]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 6 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8745, 0.4157]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 7 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7759, 0.4972]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 8 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6779, 0.1462]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 9 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7460, 0.4841]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 10 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8313, 0.3429]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 11 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.9021, 0.2544]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 12 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8262, 0.3175]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 13 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6919, 0.5921]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 14 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8039, 0.2942]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 15 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.5753, 0.6754]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 16 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.7193, 0.4400]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 17 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8108, 0.8412]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 18 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6810, 0.5893]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 19 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.8916, 0.4766]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
output length 20
output tensor([[0.8214, 0.5659],
        [0.6871, 0.3903],
        [0.5410, 0.1635],
        [0.6328, 0.3244],
        [0.8015, 0.8223],
        [0.7505, 0.5803],
        [0.8745, 0.4157],
        [0.7759, 0.4972],
        [0.6779, 0.1462],
        [0.7460, 0.4841],
        [0.8313, 0.3429],
        [0.9021, 0.2544],
        [0.8262, 0.3175],
        [0.6919, 0.5921],
        [0.8039, 0.2942],
        [0.5753, 0.6754],
        [0.7193, 0.4400],
        [0.8108, 0.8412],
        [0.6810, 0.5893],
        [0.8916, 0.4766]], device='cuda:0', grad_fn=<CatBackward0>)
labels tensor([0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1],
       device='cuda:0')
Epoch 0:  86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 6/7 [05:41<00:56, 56.89s/it, loss=0.701, v_num=22]
        [0.5992, 0.3701],█████████████████████████████████████████▋                                                                      | 3/7 [03:07<04:10, 62.59s/it, loss=0.697, v_num=22]batch_idx 3
10  torch.Size([1, 1280])█████████████████████████████████████████▋                                                                      | 3/7 [03:07<04:10, 62.59s/it, loss=0.697, v_num=22]batch_idx 3
11  tensor([[0.7724, 0.2820]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
In Loop 19 torch.Size([1, 12]) torch.Size([12, 1280])
10  torch.Size([1, 1280])
11  tensor([[0.6605, 0.4811]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
output length 20
output tensor([[0.6513, 0.4403],
        [0.6265, 0.4699],
        [0.8442, 0.3867],
        [0.7123, 0.4498],
        [0.7316, 0.3904],
        [0.8663, 0.2756],
        [0.7696, 0.3846],
        [0.6809, 0.3542],
        [0.6437, 0.4752],
        [0.8527, 0.4848],
        [0.6611, 0.7481],
        [0.8716, 0.3734],
        [0.8734, 0.3469],
        [0.9810, 0.1815],
        [0.7292, 0.4521],
        [0.6305, 0.6460],
        [0.7399, 0.2027],
        [0.5883, 0.5447],
        [0.7724, 0.2820],
        [0.6605, 0.4811]], device='cuda:0', grad_fn=<CatBackward0>)
labels tensor([0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1],
       device='cuda:0')
Epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [05:43<00:00, 49.01s/it, loss=0.706, v_num=22]
Next Fold......
10  torch.Size([1, 1280])█████████████████████████████████████████▋                                                                      | 3/7 [03:07<04:10, 62.59s/it, loss=0.697, v_num=22]batch_idx 3