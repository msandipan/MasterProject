Number of epochs to train  1 gpu0
Start Train Script
The task:  Histologischer Subtyp  Classes:  ['Klassisch', 'DesmoNodlaer']
Image path-- /home/Mukherjee/MBlst/new_data_sets/4000
------------ Classes -------------
Number of Unique Patients 162
Number of patches all 2793
Label Frequency of patches:  [1598 1195]
Label Frequency of images given patients:  [104  58]
number of different patietns 162
Number of different Patients in Data Set 162
Patient Id [3, 6, 11, 12, 13, 15, 16, 21, 22, 28, 31, 34, 37, 38, 39, 41, 42, 46, 50, 53, 56, 58, 60, 63, 64, 71, 74, 77, 78, 79, 81, 84, 86, 87, 89, 90, 91, 93, 94, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 121, 124, 126, 131, 134, 139, 140, 143, 145, 149, 151, 157, 158, 159, 162, 164, 167, 168, 170, 171, 172, 176, 178, 179, 180, 182, 187, 188, 190, 191, 193, 194, 195, 197, 200, 201, 204, 205, 208, 209, 210, 213, 214, 216, 221, 222, 224, 227, 229, 230, 232, 238, 244, 245, 248, 249, 254, 256, 257, 258, 259, 261, 263, 270, 271, 273, 274, 275, 277, 280, 282, 284, 286, 287, 291, 292, 295, 297, 299, 302, 304, 306, 307, 309, 310, 314, 318, 320, 321, 322, 324, 325, 326, 328, 330, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 348, 349, 351] 162
175
162
After Split Config
Checking for GPU
True
 USING GPUs [0]
Evaluating on validation set during training.
Loaded pretrained weights for efficientnet-b0
Loaded pretrained weights for efficientnet-b5
/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  f"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, "
/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
print the devices cuda:0
cuda:0
Loading old model
Load old 1
Current class weights [1.57446809 2.74074074]
Current class weights with extra [1.57446809 2.74074074]
Dataset Train 148ta: |█████████████████████████████████████████████████-| 99.3% Complete
Dataset Val 344
**** Batch Size ;;: 10 [0]
The Model is  efficientnet_b0
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
******---*** MODEL LOADED TO GPU/CPU *****---***
Train all Weights
Number of training Parameters 4666495
model_type efficientnet_b0
Epoch 0:   0%|                                                                                                                                                        | 0/14 [00:00<?, ?it/s]
/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/Mukherjee/ProjectFiles/MasterProject/Base/models/_Experiment_Name_s2new/CVSet0 exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name | Type | Params
------------------------------
------------------------------
0         Trainable params
0         Non-trainable params
0         Total params
0.000     Total estimated model params size (MB)
/home/Mukherjee/anaconda3/envs/Mproject/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:233: UserWarning: You called `self.log('ensemble_count', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.
Epoch 0:   0%|                                                                                                                                                        | 0/14 [00:00<?, ?it/s]11  tensor([[0.1157, 0.0510]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1302, 0.1939]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0260, 0.1053]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0416, 0.2558]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1428, 0.4244]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1417, 0.7606]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0205, 0.3310]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0980, 0.2903]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0488, 0.1910]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0931, 0.3249]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
Layer 0 weights Parameter containing:
tensor([[ 0.0245, -0.0068, -0.0110,  ...,  0.0238,  0.0061, -0.0128],
        [ 0.0096, -0.0178, -0.0177,  ...,  0.0045, -0.0158, -0.0175]],
       device='cuda:0', requires_grad=True)
Epoch 0:   7%|████████▋                                                                                                                 | 1/14 [00:16<03:36, 16.64s/it, loss=0.732, v_num=53]11  tensor([[0.2502, 0.1694]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0896, 0.2667]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1292, 0.1966]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0785, 0.2497]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0316, 0.2645]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0956, 0.2512]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0356, 0.2734]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0943, 0.1466]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0546, 0.0957]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1363, 0.3230]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
Layer 0 weights Parameter containing:
tensor([[ 0.0244, -0.0069, -0.0111,  ...,  0.0237,  0.0060, -0.0129],
        [ 0.0097, -0.0177, -0.0176,  ...,  0.0046, -0.0157, -0.0174]],
       device='cuda:0', requires_grad=True)
Epoch 0:  14%|█████████████████▍                                                                                                        | 2/14 [00:17<01:45,  8.80s/it, loss=0.728, v_num=53]11  tensor([[0.1050, 0.3184]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2001, 0.0312]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1089, 0.1957]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0154, 0.2148]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0881, 0.1070]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0667, 0.0901]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0792, 0.0917]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1822, 0.4603]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0958, 0.5571]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0531, 0.1939]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
Layer 0 weights Parameter containing:
tensor([[ 0.0243, -0.0069, -0.0112,  ...,  0.0236,  0.0059, -0.0130],
        [ 0.0098, -0.0176, -0.0175,  ...,  0.0047, -0.0156, -0.0173]],
       device='cuda:0', requires_grad=True)
Epoch 0:  21%|██████████████████████████▏                                                                                               | 3/14 [00:18<01:07,  6.17s/it, loss=0.699, v_num=53]11  tensor([[0.3671, 0.0643]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1279, 0.3576]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.4132, 0.1217]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1303, 0.0782]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1093, 0.0885]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1424, 0.1830]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2300, 0.0703]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0854, 0.1831]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2327, 0.1527]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0828, 0.5017]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
Layer 0 weights Parameter containing:
tensor([[ 0.0242, -0.0070, -0.0112,  ...,  0.0236,  0.0059, -0.0130],
        [ 0.0099, -0.0176, -0.0175,  ...,  0.0048, -0.0156, -0.0172]],
       device='cuda:0', requires_grad=True)
Epoch 0:  29%|██████████████████████████████████▊                                                                                       | 4/14 [00:19<00:48,  4.84s/it, loss=0.698, v_num=53]11  tensor([[0.1236, 0.7147]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0754, 0.0477]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1669, 0.2712]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0639, 0.0980]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1000, 0.1142]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0535, 0.1651]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2228, 0.1353]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1161, 0.2316]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2079, 0.1343]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.3077, 0.1375]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
Layer 0 weights Parameter containing:
tensor([[ 0.0242, -0.0070, -0.0112,  ...,  0.0236,  0.0059, -0.0130],
        [ 0.0100, -0.0176, -0.0175,  ...,  0.0048, -0.0156, -0.0172]],
       device='cuda:0', requires_grad=True)
Epoch 0:  36%|███████████████████████████████████████████▌                                                                              | 5/14 [00:28<00:51,  5.77s/it, loss=0.705, v_num=53]11  tensor([[0.0421, 0.2307]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0834, 0.1590]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0654, 0.3240]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2052, 0.1659]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2142, 0.1212]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1420, 0.2049]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0574, 0.0417]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1580, 0.0296]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1281, 0.4411]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.4264, 0.2123]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
Layer 0 weights Parameter containing:
tensor([[ 0.0241, -0.0070, -0.0112,  ...,  0.0236,  0.0059, -0.0130],
        [ 0.0100, -0.0176, -0.0175,  ...,  0.0048, -0.0155, -0.0172]],
       device='cuda:0', requires_grad=True)
11  tensor([[0.0814, 0.0154]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])                                          | 6/14 [00:29<00:39,  4.97s/it, loss=0.701, v_num=53]11  tensor([[0.1011, 0.2222]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0492, 0.4886]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.3064, 0.1343]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2520, 0.0812]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0534, 0.0424]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.4170, 0.0867]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0329, 0.0671]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.3449, 0.1164]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2998, 0.0697]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0825, 0.1850]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
Layer 0 weights Parameter containing:
tensor([[ 0.0240, -0.0070, -0.0112,  ...,  0.0236,  0.0060, -0.0130],
        [ 0.0101, -0.0175, -0.0175,  ...,  0.0048, -0.0155, -0.0172]],
       device='cuda:0', requires_grad=True)
Epoch 0:  50%|█████████████████████████████████████████████████████████████                                                             | 7/14 [00:30<00:30,  4.39s/it, loss=0.694, v_num=53]11  tensor([[0.5466, 0.3582]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1190, 0.0321]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0263, 0.4491]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0917, 0.0497]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1099, 0.1603]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2098, 0.1023]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0814, 0.0154]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])                                          | 6/14 [00:29<00:39,  4.97s/it, loss=0.701, v_num=53]11  tensor([[0.1011, 0.2222]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0634, 0.2824]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0619, 0.1976]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1126, 0.1259]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
Layer 0 weights Parameter containing:
tensor([[ 0.0240, -0.0070, -0.0112,  ...,  0.0236,  0.0060, -0.0130],
        [ 0.0101, -0.0175, -0.0175,  ...,  0.0048, -0.0156, -0.0172]],
       device='cuda:0', requires_grad=True)
Epoch 0:  71%|██████████████████████████████████████████████████████████████████████████████████████▍                                  | 10/14 [00:41<00:16,  4.17s/it, loss=0.698, v_num=53]11  tensor([[0.2315, 0.0528]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1290, 0.0766]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2244, 0.1540]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0671, 0.0653]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0352, 0.0260]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0703, 0.3845]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.5566, 0.2112]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.4179, 0.0964]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1583, 0.3212]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0407, 0.1601]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
Layer 0 weights Parameter containing:
tensor([[ 0.0240, -0.0069, -0.0112,  ...,  0.0237,  0.0060, -0.0129],
        [ 0.0102, -0.0176, -0.0176,  ...,  0.0048, -0.0156, -0.0172]],
       device='cuda:0', requires_grad=True)
Epoch 0:  64%|██████████████████████████████████████████████████████████████████████████████▍                                           | 9/14 [00:41<00:22,  4.56s/it, loss=0.694, v_num=53]11  tensor([[0.0252, 0.0481]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.4048, 0.0390]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2969, 0.0359]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1203, 0.0623]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2419, 0.0562]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1692, 0.1034]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1276, 0.1350]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1934, 0.2702]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0350, 0.0690]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.4581, 0.1113]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
Layer 0 weights Parameter containing:
tensor([[ 0.0240, -0.0069, -0.0112,  ...,  0.0237,  0.0061, -0.0129],
        [ 0.0102, -0.0175, -0.0176,  ...,  0.0048, -0.0156, -0.0172]],
       device='cuda:0', requires_grad=True)
Epoch 0:  71%|██████████████████████████████████████████████████████████████████████████████████████▍                                  | 10/14 [00:41<00:16,  4.17s/it, loss=0.698, v_num=53]11  tensor([[0.2315, 0.0528]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1256, 0.2416]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.4629, 0.2459]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0887, 0.2148]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1585, 0.0347]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1475, 0.2097]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2842, 0.0262]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.5225, 0.0230]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0566, 0.1544]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1095, 0.6731]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
Layer 0 weights Parameter containing:
tensor([[ 0.0240, -0.0069, -0.0112,  ...,  0.0237,  0.0061, -0.0129],
        [ 0.0102, -0.0176, -0.0176,  ...,  0.0048, -0.0156, -0.0172]],
       device='cuda:0', requires_grad=True)
Epoch 0:  79%|███████████████████████████████████████████████████████████████████████████████████████████████                          | 11/14 [00:42<00:11,  3.84s/it, loss=0.697, v_num=53]11  tensor([[0.1242, 0.0597]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.6362, 0.1031]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0198, 0.1462]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0591, 0.0608]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1598, 0.0897]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1039, 0.2099]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1054, 0.4630]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0806, 0.0572]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.4191, 0.2501]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0504, 0.0331]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
Layer 0 weights Parameter containing:
tensor([[ 0.0240, -0.0069, -0.0112,  ...,  0.0237,  0.0061, -0.0128],
        [ 0.0103, -0.0176, -0.0176,  ...,  0.0048, -0.0156, -0.0172]],
       device='cuda:0', requires_grad=True)
Epoch 0:  86%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                 | 12/14 [00:42<00:07,  3.56s/it, loss=0.696, v_num=53]11  tensor([[0.1233, 0.1590]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1549, 0.0489]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0475, 0.0771]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1138, 0.1478]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2105, 0.0160]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0989, 0.4799]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2466, 0.3166]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0989, 0.1059]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1631, 0.0649]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1383, 0.0689]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
Layer 0 weights Parameter containing:
tensor([[ 0.0240, -0.0068, -0.0112,  ...,  0.0238,  0.0061, -0.0128],
        [ 0.0103, -0.0176, -0.0176,  ...,  0.0048, -0.0156, -0.0172]],
       device='cuda:0', requires_grad=True)
Epoch 0:  93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎        | 13/14 [00:49<00:03,  3.82s/it, loss=0.694, v_num=53]11  tensor([[0.1370, 0.1845]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.0541, 0.0704]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1834, 0.0203]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.2242, 0.0780]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1686, 0.0558]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1222, 0.1367]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1235, 0.0481]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1907, 0.2671]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.3315, 0.0923]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
11  tensor([[0.1698, 0.2778]], device='cuda:0', grad_fn=<SigmoidBackward0>) torch.Size([1, 2])
Layer 0 weights Parameter containing:
tensor([[ 0.0240, -0.0068, -0.0112,  ...,  0.0238,  0.0061, -0.0128],
        [ 0.0103, -0.0176, -0.0176,  ...,  0.0048, -0.0156, -0.0172]],
       device='cuda:0', requires_grad=True)
Epoch 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:50<00:00,  3.57s/it, loss=0.692, v_num=53]
`Trainer.fit` stopped: `max_epochs=1` reached.
Next Fold......
----------------------------------------------
----------------------------------------------
-------------------------------------------------
Mean over all Folds Last
-------------------------------------------------